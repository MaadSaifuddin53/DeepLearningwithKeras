{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Problem .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaadSaifuddin53/DeepLearningwithKeras/blob/master/MNIST_Problem_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3b6ebvyQvxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import sklearn\n",
        "from keras import layers,models,optimizers,losses,activations,regularizers,initializers\n",
        "from keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder        # for label encoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers.normalization  import BatchNormalization\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.layers import Activation\n",
        "from keras import regularizers\n",
        "from keras.layers import Dropout \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBRdxiS4mDf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed=7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0-hsO0mBUoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0_27X2PJmIw",
        "colab_type": "text"
      },
      "source": [
        " **Loading Data**\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp4MWv8gCLCt",
        "colab_type": "code",
        "outputId": "0c0b268f-b879-4f9b-ac21-46563a6ef750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(train_data,train_label), (test_data,test_labels)=mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bWSgYPjCdZh",
        "colab_type": "code",
        "outputId": "848a21c9-e1bd-4fb9-fcd4-7853ac6e52bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkrUJ2odEEBd",
        "colab_type": "code",
        "outputId": "9fddf48e-ef22-466e-ae6e-a96efd6e96e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUrdpdoTJaa3",
        "colab_type": "text"
      },
      "source": [
        "**Normalizing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKPpm4SIGpv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.reshape((60000,28*28))\n",
        "train_data = train_data.astype(\"float32\")/255\n",
        "\n",
        "test_data =  test_data.reshape((10000,28*28))\n",
        "test_data =  test_data.astype(\"float32\")/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVw_MHzxKLC_",
        "colab_type": "text"
      },
      "source": [
        "**Preparing the label**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9hrNr3RKImH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label = to_categorical(train_label)\n",
        "test_label  =  to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwG-mPieM-E-",
        "colab_type": "text"
      },
      "source": [
        "**Train validation split**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn8fOJYdWIo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data   = train_data[:50000]\n",
        "val_data = train_data[50000 : ]\n",
        "\n",
        "x_label = train_label[:50000]\n",
        "val_label = train_label[50000:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMvGdb2LM4hc",
        "colab_type": "code",
        "outputId": "ed397f27-890c-4b22-c7ae-75ebf762dde0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(x_data.shape)\n",
        "print(val_data.shape)\n",
        "print(x_label.shape)\n",
        "print(val_label.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n",
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW3uVR5SXkVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5BNXQ21EsL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseLineModel():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer='Adam',loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-w2axzYZS1C",
        "colab_type": "code",
        "outputId": "5c66e419-df37-46fb-e373-6a534e59dfa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=baseLineModel()\n",
        "history = model.fit(x_data,x_label,epochs=50,batch_size=128,validation_data=(val_data,val_label))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0801 07:18:10.499284 139950953265024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0801 07:18:10.538208 139950953265024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0801 07:18:10.545438 139950953265024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0801 07:18:10.580577 139950953265024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0801 07:18:10.608731 139950953265024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0801 07:18:10.741402 139950953265024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0801 07:18:10.793018 139950953265024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 2s 34us/step - loss: 0.6737 - acc: 0.8117 - val_loss: 0.3129 - val_acc: 0.9160\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 1s 21us/step - loss: 0.3085 - acc: 0.9124 - val_loss: 0.2626 - val_acc: 0.9242\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 1s 19us/step - loss: 0.2690 - acc: 0.9240 - val_loss: 0.2411 - val_acc: 0.9310\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.2480 - acc: 0.9296 - val_loss: 0.2300 - val_acc: 0.9335\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.2329 - acc: 0.9344 - val_loss: 0.2176 - val_acc: 0.9373\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.2213 - acc: 0.9371 - val_loss: 0.2097 - val_acc: 0.9411\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.2109 - acc: 0.9395 - val_loss: 0.2060 - val_acc: 0.9424\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.2010 - acc: 0.9430 - val_loss: 0.1974 - val_acc: 0.9433\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1944 - acc: 0.9436 - val_loss: 0.1935 - val_acc: 0.9466\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1870 - acc: 0.9465 - val_loss: 0.1901 - val_acc: 0.9465\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1810 - acc: 0.9477 - val_loss: 0.1846 - val_acc: 0.9486\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 1s 19us/step - loss: 0.1761 - acc: 0.9499 - val_loss: 0.1883 - val_acc: 0.9493\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1711 - acc: 0.9511 - val_loss: 0.1809 - val_acc: 0.9497\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1671 - acc: 0.9526 - val_loss: 0.1787 - val_acc: 0.9504\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1634 - acc: 0.9534 - val_loss: 0.1786 - val_acc: 0.9504\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1598 - acc: 0.9542 - val_loss: 0.1776 - val_acc: 0.9493\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1569 - acc: 0.9552 - val_loss: 0.1796 - val_acc: 0.9495\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1538 - acc: 0.9567 - val_loss: 0.1729 - val_acc: 0.9510\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1510 - acc: 0.9568 - val_loss: 0.1780 - val_acc: 0.9483\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1488 - acc: 0.9578 - val_loss: 0.1739 - val_acc: 0.9507\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1460 - acc: 0.9585 - val_loss: 0.1708 - val_acc: 0.9525\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1438 - acc: 0.9592 - val_loss: 0.1736 - val_acc: 0.9523\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1416 - acc: 0.9594 - val_loss: 0.1708 - val_acc: 0.9539\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 1s 19us/step - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1688 - val_acc: 0.9524\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1373 - acc: 0.9605 - val_loss: 0.1680 - val_acc: 0.9535\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1351 - acc: 0.9611 - val_loss: 0.1709 - val_acc: 0.9528\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1337 - acc: 0.9621 - val_loss: 0.1697 - val_acc: 0.9539\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1318 - acc: 0.9625 - val_loss: 0.1699 - val_acc: 0.9529\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1306 - acc: 0.9629 - val_loss: 0.1685 - val_acc: 0.9517\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1284 - acc: 0.9635 - val_loss: 0.1699 - val_acc: 0.9519\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1272 - acc: 0.9636 - val_loss: 0.1702 - val_acc: 0.9517\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1255 - acc: 0.9640 - val_loss: 0.1727 - val_acc: 0.9506\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1243 - acc: 0.9642 - val_loss: 0.1693 - val_acc: 0.9527\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1235 - acc: 0.9641 - val_loss: 0.1717 - val_acc: 0.9515\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 1s 19us/step - loss: 0.1212 - acc: 0.9649 - val_loss: 0.1686 - val_acc: 0.9531\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1208 - acc: 0.9656 - val_loss: 0.1721 - val_acc: 0.9529\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1195 - acc: 0.9661 - val_loss: 0.1731 - val_acc: 0.9522\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1187 - acc: 0.9660 - val_loss: 0.1673 - val_acc: 0.9534\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1168 - acc: 0.9673 - val_loss: 0.1716 - val_acc: 0.9516\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1160 - acc: 0.9663 - val_loss: 0.1729 - val_acc: 0.9506\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1156 - acc: 0.9670 - val_loss: 0.1697 - val_acc: 0.9531\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1139 - acc: 0.9672 - val_loss: 0.1701 - val_acc: 0.9536\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 1s 19us/step - loss: 0.1121 - acc: 0.9682 - val_loss: 0.1721 - val_acc: 0.9509\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1113 - acc: 0.9683 - val_loss: 0.1704 - val_acc: 0.9537\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1101 - acc: 0.9685 - val_loss: 0.1729 - val_acc: 0.9517\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1098 - acc: 0.9689 - val_loss: 0.1747 - val_acc: 0.9523\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 1s 19us/step - loss: 0.1083 - acc: 0.9689 - val_loss: 0.1729 - val_acc: 0.9523\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1081 - acc: 0.9692 - val_loss: 0.1706 - val_acc: 0.9521\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1073 - acc: 0.9696 - val_loss: 0.1721 - val_acc: 0.9530\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 1s 18us/step - loss: 0.1055 - acc: 0.9697 - val_loss: 0.1729 - val_acc: 0.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAovN-fGenxz",
        "colab_type": "code",
        "outputId": "efa95fb3-f00d-4e5d-ee7e-f8aa7d2209f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss,test_acc = model.evaluate(test_data,test_label)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 19us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox0nRQGAfprF",
        "colab_type": "code",
        "outputId": "0c0b2bc7-80d2-4e96-9e83-53f1af6e3887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "print(\"test_loss  \" , (test_loss*100))\n",
        "print(\"test_accuracy  \" ,(test_acc*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_loss   17.90727335933596\n",
            "test_accuracy   95.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGM9R295klIE",
        "colab_type": "text"
      },
      "source": [
        "**Using stratified k fold and cross validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAKOWIgalUHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading Data\n",
        "(train_data,train_label), (test_data,test_labels)=mnist.load_data()\n",
        "\n",
        "#Normalizing Data \n",
        "train_data = train_data.reshape((60000,28*28))\n",
        "train_data = train_data.astype(\"float32\")/255\n",
        "test_data =  test_data.reshape((10000,28*28))\n",
        "test_data =  test_data.astype(\"float32\")/255\n",
        "\n",
        "#one hot Encoding\n",
        "train_label = to_categorical(train_label)\n",
        "test_label  =  to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqiigI62kkpw",
        "colab_type": "code",
        "outputId": "478bcc73-da81-4af2-caea-7a02639d8421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "estimator=KerasClassifier(build_fn=baseLineModel,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 94.87% (0.30%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdjW5eWZkiD_",
        "colab_type": "code",
        "outputId": "68c3b61b-b3b2-42dd-f59f-8117965c6657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def largeModel():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=largeModel,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 92.51% (0.30%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjGz2sJzpdnT",
        "colab_type": "code",
        "outputId": "331edbbc-1a14-4b8e-c551-8b441253d5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def largeModel1():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=largeModel1,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 93.51% (0.81%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HldAP9D3_19h",
        "colab_type": "code",
        "outputId": "e67b3ad2-bb5f-4467-b764-91c258f6a51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def largeModel2():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(2,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=largeModel2,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 79.84% (11.36%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofte7RDtGIJX",
        "colab_type": "code",
        "outputId": "425d178e-c494-4fd6-9130-d736810a4859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def largeModel3():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(6,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=largeModel3,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 92.64% (1.43%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5HxYccpK3nu",
        "colab_type": "code",
        "outputId": "cfa01284-4aa9-4c46-efe4-801429a86bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def largeModel4():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=largeModel4,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 96.13% (0.51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiGP3HN1mjPA",
        "colab_type": "code",
        "outputId": "d6c4118b-ba51-4ae2-f2de-130ced8fc3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def fullyScaledModel():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 98.08% (0.26%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO7ijByo2Lp8",
        "colab_type": "text"
      },
      "source": [
        "**Apply Regularizer techinque l2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "416ab4wj2IGb",
        "colab_type": "code",
        "outputId": "61dd943e-977a-4335-a75c-e7769db3bfd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel1():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel1,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 90.72% (6.17%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKJ7b4ljRA9d",
        "colab_type": "text"
      },
      "source": [
        "**Using DropOut**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QexMgheUI9Ty",
        "colab_type": "code",
        "outputId": "9c6cf776-bca9-4b39-d27c-1df343427bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel2():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel2,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 12:18:42.289769 140488653084544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0802 12:18:42.336521 140488653084544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0802 12:18:42.344637 140488653084544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0802 12:18:42.380501 140488653084544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0802 12:18:42.395050 140488653084544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0802 12:18:42.694566 140488653084544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0802 12:18:42.722186 140488653084544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0802 12:18:43.011865 140488653084544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results: 41.79% (2.42%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP4Q0rpVk5lH",
        "colab_type": "code",
        "outputId": "4e7fa622-a6d1-4061-a5a3-8195b5913436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel3():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel3,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 87.39% (7.50%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XbKsLS-9MDx",
        "colab_type": "text"
      },
      "source": [
        "**Using l1 regularizers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3C-xF8_8Pvh",
        "colab_type": "code",
        "outputId": "aa550f7b-a74c-4fdd-9a8a-dec3ddd191cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel4():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l1(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel4,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 56.29% (37.16%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmfQGNW2bDBx",
        "colab_type": "text"
      },
      "source": [
        "**Dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNKE9gGxbpgz",
        "colab_type": "code",
        "outputId": "b988678d-3de8-471a-b68d-4d8df16144c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel5():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.15))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.1))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.025))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(layers.Dropout(0.025))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel5,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0803 06:19:22.761116 140142841116544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0803 06:19:22.792814 140142841116544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0803 06:19:22.799646 140142841116544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0803 06:19:22.822903 140142841116544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0803 06:19:22.834155 140142841116544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0803 06:19:23.082894 140142841116544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0803 06:19:23.109343 140142841116544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0803 06:19:23.245971 140142841116544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results: 97.37% (0.43%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb6nUpGhYZn1",
        "colab_type": "text"
      },
      "source": [
        "**l2 reg with 0.001**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrBPe4VtYXeJ",
        "colab_type": "code",
        "outputId": "6aa06e61-67d7-4e2a-c846-ddc4065e502c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel6():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel6,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 10:45:33.344970 140592620791680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0804 10:45:33.389245 140592620791680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0804 10:45:33.398245 140592620791680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0804 10:45:33.583707 140592620791680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0804 10:45:33.612839 140592620791680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0804 10:45:33.896462 140592620791680 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0804 10:45:34.000699 140592620791680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results: 96.83% (0.36%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF3HOcmtdbuw",
        "colab_type": "code",
        "outputId": "e1e62a07-be91-4f7c-8a6c-1ad75f707029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel7():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(200,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.001)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel7,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 96.91% (0.43%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYgmjWz03OWk",
        "colab_type": "text"
      },
      "source": [
        "**L2 regilarizer with 0.01 value**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73A7QCNf3GVf",
        "colab_type": "code",
        "outputId": "06aff29d-ab94-4928-c78f-baf2ba0b7768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "\n",
        "def fullyScaledModel8():\n",
        "  model= models.Sequential()\n",
        "  model.add(layers.Dense(512,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01),input_shape=(28*28,)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(256,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(200,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(128,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(64,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(32,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(16,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(8,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  model.add(layers.Dense(4,kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01)))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "  \n",
        "  model.add(layers.Dense(10,kernel_initializer='glorot_uniform'))\n",
        "  BatchNormalization()\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "  return model  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=fullyScaledModel8,epochs=50,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 10:13:42.620356 140220266674048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0805 10:13:42.657448 140220266674048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0805 10:13:42.665500 140220266674048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0805 10:13:42.869753 140220266674048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0805 10:13:42.896620 140220266674048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0805 10:13:43.181761 140220266674048 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0805 10:13:43.280928 140220266674048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results: 80.64% (23.40%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bQMgMvTw2Zp",
        "colab_type": "text"
      },
      "source": [
        "# **Tuned Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPvLtI4PQ6_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d597a5c6-8fbd-4818-c88e-6b8a911ece8c"
      },
      "source": [
        "def TunnedModel():\n",
        "  \n",
        "    model= models.Sequential()\n",
        "    model.add(layers.Dense(512,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001),input_shape=(28*28,)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(256,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(16,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "    model.add(layers.Dense(8,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "    model.add(layers.Dense(4,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(10,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"softmax\"))\n",
        "  \n",
        "    opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "    return model  \n",
        "  \n",
        "  \n",
        "  \n",
        "# Model Traning   \n",
        "estimator=KerasClassifier(build_fn=TunnedModel,epochs=70,batch_size=128,verbose=0)\n",
        "kfold= KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, train_data, train_label, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results: 98.08% (0.21%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nyegXrRp6R5",
        "colab_type": "text"
      },
      "source": [
        "# **Without K fold strategy train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6_FWmup5wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b35e5638-fe05-47ab-df4d-f4a59676185b"
      },
      "source": [
        "def TunnedModel():\n",
        "  \n",
        "    model= models.Sequential()\n",
        "    model.add(layers.Dense(512,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001),input_shape=(28*28,)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(256,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(16,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "    model.add(layers.Dense(8,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "  \n",
        "    model.add(layers.Dense(4,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"relu\"))\n",
        "  \n",
        "    model.add(layers.Dense(10,kernel_initializer='glorot_normal',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "    BatchNormalization()\n",
        "    model.add(Activation(\"softmax\"))\n",
        "  \n",
        "    opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "    model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['acc'])\n",
        "    return model  \n",
        "  \n",
        "  \n",
        "  \n",
        "model=TunnedModel()\n",
        "history = model.fit(train_data, train_label,epochs=70,batch_size=128,shuffle=True,validation_split=0.2)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/70\n",
            "48000/48000 [==============================] - 13s 277us/step - loss: 1.6769 - acc: 0.3297 - val_loss: 1.3491 - val_acc: 0.4987\n",
            "Epoch 2/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 1.1823 - acc: 0.5931 - val_loss: 1.0244 - val_acc: 0.6618\n",
            "Epoch 3/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.8997 - acc: 0.6850 - val_loss: 0.7906 - val_acc: 0.7514\n",
            "Epoch 4/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.6054 - acc: 0.8528 - val_loss: 0.5654 - val_acc: 0.8603\n",
            "Epoch 5/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.4759 - acc: 0.8722 - val_loss: 0.4640 - val_acc: 0.8822\n",
            "Epoch 6/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.3604 - acc: 0.9439 - val_loss: 0.3616 - val_acc: 0.9513\n",
            "Epoch 7/70\n",
            "48000/48000 [==============================] - 8s 173us/step - loss: 0.2686 - acc: 0.9635 - val_loss: 0.3526 - val_acc: 0.9411\n",
            "Epoch 8/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.2346 - acc: 0.9678 - val_loss: 0.3056 - val_acc: 0.9623\n",
            "Epoch 9/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.1866 - acc: 0.9746 - val_loss: 0.2802 - val_acc: 0.9630\n",
            "Epoch 10/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.1603 - acc: 0.9782 - val_loss: 0.2494 - val_acc: 0.9675\n",
            "Epoch 11/70\n",
            "48000/48000 [==============================] - 8s 165us/step - loss: 0.1280 - acc: 0.9806 - val_loss: 0.2540 - val_acc: 0.9653\n",
            "Epoch 12/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.1203 - acc: 0.9803 - val_loss: 0.2300 - val_acc: 0.9672\n",
            "Epoch 13/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.1208 - acc: 0.9807 - val_loss: 0.2265 - val_acc: 0.9619\n",
            "Epoch 14/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0996 - acc: 0.9851 - val_loss: 0.2478 - val_acc: 0.9627\n",
            "Epoch 15/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.1058 - acc: 0.9848 - val_loss: 0.2201 - val_acc: 0.9714\n",
            "Epoch 16/70\n",
            "48000/48000 [==============================] - 8s 162us/step - loss: 0.0985 - acc: 0.9854 - val_loss: 0.2010 - val_acc: 0.9707\n",
            "Epoch 17/70\n",
            "48000/48000 [==============================] - 8s 164us/step - loss: 0.0789 - acc: 0.9897 - val_loss: 0.2225 - val_acc: 0.9733\n",
            "Epoch 18/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0769 - acc: 0.9909 - val_loss: 0.2138 - val_acc: 0.9728\n",
            "Epoch 19/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0815 - acc: 0.9897 - val_loss: 0.2122 - val_acc: 0.9716\n",
            "Epoch 20/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0752 - acc: 0.9909 - val_loss: 0.2121 - val_acc: 0.9739\n",
            "Epoch 21/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.1126 - acc: 0.9833 - val_loss: 0.2143 - val_acc: 0.9689\n",
            "Epoch 22/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0816 - acc: 0.9908 - val_loss: 0.2304 - val_acc: 0.9694\n",
            "Epoch 23/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0776 - acc: 0.9910 - val_loss: 0.2084 - val_acc: 0.9751\n",
            "Epoch 24/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0648 - acc: 0.9938 - val_loss: 0.2122 - val_acc: 0.9764\n",
            "Epoch 25/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0754 - acc: 0.9916 - val_loss: 0.1940 - val_acc: 0.9760\n",
            "Epoch 26/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0604 - acc: 0.9948 - val_loss: 0.2032 - val_acc: 0.9745\n",
            "Epoch 27/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0619 - acc: 0.9945 - val_loss: 0.2057 - val_acc: 0.9753\n",
            "Epoch 28/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0777 - acc: 0.9911 - val_loss: 0.1888 - val_acc: 0.9740\n",
            "Epoch 29/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0696 - acc: 0.9926 - val_loss: 0.2041 - val_acc: 0.9750\n",
            "Epoch 30/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0621 - acc: 0.9940 - val_loss: 0.2430 - val_acc: 0.9717\n",
            "Epoch 31/70\n",
            "48000/48000 [==============================] - 8s 173us/step - loss: 0.0554 - acc: 0.9958 - val_loss: 0.2176 - val_acc: 0.9768\n",
            "Epoch 32/70\n",
            "48000/48000 [==============================] - 8s 172us/step - loss: 0.0530 - acc: 0.9963 - val_loss: 0.2419 - val_acc: 0.9765\n",
            "Epoch 33/70\n",
            "48000/48000 [==============================] - 8s 172us/step - loss: 0.0621 - acc: 0.9945 - val_loss: 0.2124 - val_acc: 0.9736\n",
            "Epoch 34/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0580 - acc: 0.9952 - val_loss: 0.1989 - val_acc: 0.9772\n",
            "Epoch 35/70\n",
            "48000/48000 [==============================] - 8s 172us/step - loss: 0.0574 - acc: 0.9949 - val_loss: 0.2428 - val_acc: 0.9730\n",
            "Epoch 36/70\n",
            "48000/48000 [==============================] - 8s 171us/step - loss: 0.0630 - acc: 0.9942 - val_loss: 0.2039 - val_acc: 0.9753\n",
            "Epoch 37/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0549 - acc: 0.9960 - val_loss: 0.2398 - val_acc: 0.9764\n",
            "Epoch 38/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0526 - acc: 0.9965 - val_loss: 0.2079 - val_acc: 0.9769\n",
            "Epoch 39/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0496 - acc: 0.9967 - val_loss: 0.2220 - val_acc: 0.9758\n",
            "Epoch 40/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0524 - acc: 0.9961 - val_loss: 0.1987 - val_acc: 0.9775\n",
            "Epoch 41/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0491 - acc: 0.9969 - val_loss: 0.1976 - val_acc: 0.9772\n",
            "Epoch 42/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0668 - acc: 0.9941 - val_loss: 0.1908 - val_acc: 0.9782\n",
            "Epoch 43/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0596 - acc: 0.9948 - val_loss: 0.1935 - val_acc: 0.9773\n",
            "Epoch 44/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0566 - acc: 0.9954 - val_loss: 0.1905 - val_acc: 0.9780\n",
            "Epoch 45/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0489 - acc: 0.9973 - val_loss: 0.1925 - val_acc: 0.9747\n",
            "Epoch 46/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0480 - acc: 0.9972 - val_loss: 0.2091 - val_acc: 0.9768\n",
            "Epoch 47/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0467 - acc: 0.9973 - val_loss: 0.2018 - val_acc: 0.9787\n",
            "Epoch 48/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0499 - acc: 0.9971 - val_loss: 0.2070 - val_acc: 0.9758\n",
            "Epoch 49/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0488 - acc: 0.9968 - val_loss: 0.2079 - val_acc: 0.9769\n",
            "Epoch 50/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0466 - acc: 0.9973 - val_loss: 0.2232 - val_acc: 0.9763\n",
            "Epoch 51/70\n",
            "48000/48000 [==============================] - 8s 171us/step - loss: 0.0563 - acc: 0.9957 - val_loss: 0.2093 - val_acc: 0.9762\n",
            "Epoch 52/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0497 - acc: 0.9970 - val_loss: 0.2069 - val_acc: 0.9773\n",
            "Epoch 53/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0497 - acc: 0.9971 - val_loss: 0.1998 - val_acc: 0.9775\n",
            "Epoch 54/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0437 - acc: 0.9977 - val_loss: 0.2052 - val_acc: 0.9763\n",
            "Epoch 55/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0510 - acc: 0.9962 - val_loss: 0.2142 - val_acc: 0.9745\n",
            "Epoch 56/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0502 - acc: 0.9967 - val_loss: 0.1930 - val_acc: 0.9763\n",
            "Epoch 57/70\n",
            "48000/48000 [==============================] - 8s 166us/step - loss: 0.0414 - acc: 0.9982 - val_loss: 0.1933 - val_acc: 0.9783\n",
            "Epoch 58/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0457 - acc: 0.9971 - val_loss: 0.1792 - val_acc: 0.9800\n",
            "Epoch 59/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0420 - acc: 0.9978 - val_loss: 0.1892 - val_acc: 0.9768\n",
            "Epoch 60/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0486 - acc: 0.9965 - val_loss: 0.2205 - val_acc: 0.9753\n",
            "Epoch 61/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0535 - acc: 0.9959 - val_loss: 0.1865 - val_acc: 0.9793\n",
            "Epoch 62/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0446 - acc: 0.9973 - val_loss: 0.2060 - val_acc: 0.9732\n",
            "Epoch 63/70\n",
            "48000/48000 [==============================] - 8s 170us/step - loss: 0.0466 - acc: 0.9971 - val_loss: 0.1787 - val_acc: 0.9797\n",
            "Epoch 64/70\n",
            "48000/48000 [==============================] - 8s 164us/step - loss: 0.0395 - acc: 0.9985 - val_loss: 0.1834 - val_acc: 0.9797\n",
            "Epoch 65/70\n",
            "48000/48000 [==============================] - 8s 167us/step - loss: 0.0430 - acc: 0.9976 - val_loss: 0.2164 - val_acc: 0.9759\n",
            "Epoch 66/70\n",
            "48000/48000 [==============================] - 8s 168us/step - loss: 0.0611 - acc: 0.9947 - val_loss: 0.1620 - val_acc: 0.9770\n",
            "Epoch 67/70\n",
            "48000/48000 [==============================] - 8s 169us/step - loss: 0.0431 - acc: 0.9975 - val_loss: 0.1660 - val_acc: 0.9812\n",
            "Epoch 68/70\n",
            "48000/48000 [==============================] - 8s 171us/step - loss: 0.0390 - acc: 0.9984 - val_loss: 0.1793 - val_acc: 0.9791\n",
            "Epoch 69/70\n",
            "48000/48000 [==============================] - 8s 175us/step - loss: 0.0447 - acc: 0.9975 - val_loss: 0.2169 - val_acc: 0.9751\n",
            "Epoch 70/70\n",
            "48000/48000 [==============================] - 8s 174us/step - loss: 0.0402 - acc: 0.9980 - val_loss: 0.2034 - val_acc: 0.9764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8nawyA3IaSN",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20fjPKh6vm6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f0f85d44-becf-45bf-9ba2-a1a6cd50f5bd"
      },
      "source": [
        "test_loss,test_acc = model.evaluate(test_data,test_label)\n",
        "print(\"test_loss  \" , (test_loss*100))\n",
        "print(\"test_accuracy  \" ,(test_acc*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 134us/step\n",
            "test_loss   18.29698614448309\n",
            "test_accuracy   97.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uN-ph55z3i0",
        "colab_type": "text"
      },
      "source": [
        "# *Ploting loss and accuracy of training and validation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnqsCrkMwMrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "9e26fbec-8675-40f6-969d-57e7ece54ccb"
      },
      "source": [
        "accuracy = history.history['acc']\n",
        "val_accuracy = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY0wS+v+pPfhaCwnb+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaGRrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOC6lWfkIOXX",
        "colab_type": "text"
      },
      "source": [
        "# **Model Saving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Msoxxa5xpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"TunnedModel1.h5py\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOBehabz9RAg",
        "colab_type": "text"
      },
      "source": [
        "# **Making prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNauePrH6vvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6ea622c7-f71d-4572-a83d-dcd4591f5d9d"
      },
      "source": [
        "model.predict(test_data[:4])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 0.0000000e+00, 2.9635904e-23, 5.0951676e-06,\n",
              "        1.2882010e-08, 9.0441992e-09, 5.6851572e-26, 9.9999487e-01,\n",
              "        4.5052382e-29, 6.3005747e-09],\n",
              "       [9.9617048e-37, 0.0000000e+00, 9.9999583e-01, 1.6176057e-19,\n",
              "        4.1146473e-06, 4.1926475e-26, 2.2115425e-21, 5.1207191e-11,\n",
              "        1.4731994e-36, 2.7128039e-13],\n",
              "       [8.1688300e-32, 1.0000000e+00, 0.0000000e+00, 5.7519358e-19,\n",
              "        0.0000000e+00, 1.3483778e-12, 0.0000000e+00, 9.2634020e-36,\n",
              "        7.9793265e-09, 2.8948781e-37],\n",
              "       [9.9999726e-01, 0.0000000e+00, 0.0000000e+00, 1.1700062e-10,\n",
              "        8.2416973e-19, 1.6454504e-37, 0.0000000e+00, 1.4495878e-20,\n",
              "        8.5658840e-13, 2.7437065e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gty44uoQ9WUD",
        "colab_type": "text"
      },
      "source": [
        "# **Checking Prediction result from test label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSf_DxdU8zaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3fea8cd2-91b6-4a7c-faca-24368d74b55a"
      },
      "source": [
        "#actual results for first 4 images in test set\n",
        "test_label[:4]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSuuU0ZfD5o3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb7fc0a3-5503-46bb-df29-4579cdf3eb8c"
      },
      "source": [
        "predicted_classes = model.predict(test_data)\n",
        "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "predicted_classes.shape,test_labels.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28cQyXWcBFiS",
        "colab_type": "text"
      },
      "source": [
        "# **Plotting charts of correct and incorret labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrOQqKy178rT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "1311e62d-e547-4e20-abb8-96d843df851b"
      },
      "source": [
        "correct = np.where(predicted_classes==test_labels)[0]\n",
        "print (\"Found %d correct labels\" %  len(correct))\n",
        "for i, correct in enumerate(correct[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(test_data[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], test_labels[correct]))\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9783 correct labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEYCAYAAACUdWs9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVtYVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4OWBXkVAF2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "2dfb070e-a9ce-4c01-e625-c39aa1d25588"
      },
      "source": [
        "incorrect = np.where(predicted_classes!=test_labels)[0]\n",
        "print (\"Found %d incorrect labels\" %  len(incorrect))\n",
        "for i, incorrect in enumerate(incorrect[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(test_data[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], test_labels[incorrect]))\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 217 incorrect labels\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEYCAYAAACUdWs9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlM4LGkpH4CA",
        "colab_type": "text"
      },
      "source": [
        "# **Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wAK8653DnK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "168e0b2b-c007-46bf-c56b-d37e9e350360"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = [\"Class {}\".format(i) for i in range(10)]\n",
        "print(classification_report(test_labels, predicted_classes, target_names=target_names))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.95      0.99      0.97       980\n",
            "     Class 1       0.99      0.99      0.99      1135\n",
            "     Class 2       0.98      0.98      0.98      1032\n",
            "     Class 3       0.96      0.98      0.97      1010\n",
            "     Class 4       0.98      0.98      0.98       982\n",
            "     Class 5       0.99      0.98      0.98       892\n",
            "     Class 6       0.99      0.98      0.99       958\n",
            "     Class 7       0.99      0.95      0.97      1028\n",
            "     Class 8       0.98      0.97      0.98       974\n",
            "     Class 9       0.97      0.97      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0xaPWGsGtIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}