{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder        # for label encoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('sonar.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataframe.values\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset[:,0:60].astype('float32')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
       "       'R', 'R', 'R', 'R', 'R', 'R', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M',\n",
       "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset[:,60]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'R'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_y=le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60,activation='relu',input_shape=(60,)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 84.18% (6.08%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x, encoded_y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate baseline model with standardized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smaller Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smaller():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,activation='relu',input_shape=(60,)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.70562846042635 7.463458112674119\n"
     ]
    }
   ],
   "source": [
    "estimator=KerasClassifier(build_fn=create_smaller,epochs=100,batch_size=5,verbose=0)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,encoded_y,cv=kfold)\n",
    "print(result.mean()*100,result.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 83.71% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Results: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_smaller,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.59% (7.99%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Larger():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60,activation='relu',input_shape=(60,)))\n",
    "    model.add(Dense(30,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 86.59% (7.59%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_Larger,epochs=100,batch_size=5,verbose=0)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,encoded_y,cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.61% (6.36%)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('Standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_Larger,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 84.61% (6.36%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Larger: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_scaled():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(512,activation='relu',input_shape=(60,)))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "estimator=[]\n",
    "estimator.append(('Standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=fully_scaled,epochs=200,batch_size=128,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled: 85.54% (6.95%)\n"
     ]
    }
   ],
   "source": [
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Fully Scaled: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model: 86.56% (8.27%)\n"
     ]
    }
   ],
   "source": [
    "def Tuned():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(512,activation='relu',input_shape=(60,)))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator=[]\n",
    "estimator.append(('Standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=Tuned,epochs=100,batch_size=128,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Tuned Model: %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    x=layers.Dense(60,activation='relu')(inputs)\n",
    "    outputs=layers.Dense(1,activation='sigmoid')(x)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result : 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=baseline_model,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Result : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small():\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    x=layers.Dense(30,activation='relu')(inputs)\n",
    "    outputs=layers.Dense(1,activation='sigmoid')(x)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small : 85.06% (7.61%)\n"
     ]
    }
   ],
   "source": [
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_small,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Small : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Larger():\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    x=layers.Dense(60,activation='relu')(inputs)\n",
    "    x=layers.Dense(30,activation='relu')(x)\n",
    "    outputs=layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger : 85.09% (5.87%)\n"
     ]
    }
   ],
   "source": [
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_Larger,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Larger : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully_scaled : 82.66% (9.22%)\n"
     ]
    }
   ],
   "source": [
    "def fully_scaled():\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    x=layers.Dense(512,activation='relu')(inputs)\n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(128,activation='relu')(x)\n",
    "    x=layers.Dense(64,activation='relu')(x)\n",
    "    x=layers.Dense(32,activation='relu')(x)\n",
    "    x=layers.Dense(16,activation='relu')(x)\n",
    "    x=layers.Dense(4,activation='relu')(x)\n",
    "    outputs=layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=fully_scaled,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Fully_scaled : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuned():\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    x=layers.Dense(90,activation='relu')(inputs)\n",
    "    x=layers.Dense(60,activation='relu')(x)\n",
    "    outputs=layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned : 82.61% (7.74%)\n"
     ]
    }
   ],
   "source": [
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_tuned,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Tuned : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sub CLassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result : 85.59% (7.46%)\n"
     ]
    }
   ],
   "source": [
    "class baseline(keras.Model):\n",
    "     def __init__(self):\n",
    "            super(baseline,self).__init__()\n",
    "            self.dense1=layers.Dense(60,activation='relu')\n",
    "            self.dense2=layers.Dense(1,activation='sigmoid')\n",
    "     def call(self,inputs):\n",
    "          x=self.dense1(inputs)\n",
    "          return self.dense2(x)\n",
    "def create_baseline():\n",
    "    inputs=keras.Input(shape=(60,))\n",
    "    Mymodel=baseline()\n",
    "    outputs=Mymodel.call(inputs)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Result : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small : 85.06% (7.61%)\n"
     ]
    }
   ],
   "source": [
    "class small(keras.Model):\n",
    "     def __init__(self):\n",
    "            super(small,self).__init__()\n",
    "            self.dense1=layers.Dense(30,activation='relu')\n",
    "            self.dense2=layers.Dense(1,activation='sigmoid')\n",
    "     def call(self,inputs):\n",
    "          x=self.dense1(inputs)\n",
    "          return self.dense2(x)\n",
    "def create_small():\n",
    "    inputs=keras.Input(shape=(60,))\n",
    "    Mymodel=small()\n",
    "    outputs=Mymodel.call(inputs)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_small,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"small : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large : 84.11% (6.11%)\n"
     ]
    }
   ],
   "source": [
    "class Larger(keras.Model):\n",
    "     def __init__(self):\n",
    "            super(Larger,self).__init__()\n",
    "            self.dense1=layers.Dense(60,activation='relu')\n",
    "            self.dense2=layers.Dense(30,activation='relu')\n",
    "            self.dense3=layers.Dense(1,activation='sigmoid')\n",
    "     def call(self,inputs):\n",
    "          x=self.dense1(inputs)\n",
    "          x=self.dense2(x)\n",
    "          return self.dense3(x)\n",
    "def create_large():\n",
    "    inputs=keras.Input(shape=(60,))\n",
    "    Mymodel=Larger()\n",
    "    outputs=Mymodel.call(inputs)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_large,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Large : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full_scaled : 85.56% (7.40%)\n"
     ]
    }
   ],
   "source": [
    "class FullScaled(keras.Model):\n",
    "     def __init__(self):\n",
    "            super(FullScaled,self).__init__()\n",
    "            self.dense1=layers.Dense(512,activation='relu')\n",
    "            self.dense2=layers.Dense(256,activation='relu')\n",
    "            self.dense3=layers.Dense(128,activation='relu')\n",
    "            self.dense4=layers.Dense(64,activation='relu')\n",
    "            self.dense5=layers.Dense(32,activation='relu')\n",
    "            self.dense6=layers.Dense(16,activation='relu')\n",
    "            self.dense7=layers.Dense(4,activation='relu')\n",
    "            self.dense8=layers.Dense(1,activation='sigmoid')\n",
    "     def call(self,inputs):\n",
    "          x=self.dense1(inputs)\n",
    "          x=self.dense2(x)\n",
    "          x=self.dense3(x)\n",
    "          x=self.dense4(x)\n",
    "          x=self.dense5(x)\n",
    "          x=self.dense6(x)\n",
    "          x=self.dense7(x)\n",
    "          return self.dense8(x)\n",
    "def create_fullScaled():\n",
    "    inputs=keras.Input(shape=(60,))\n",
    "    Mymodel=FullScaled()\n",
    "    outputs=Mymodel.call(inputs)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_fullScaled,epochs=300,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Full_scaled : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full_scaled : 82.13% (8.25%)\n"
     ]
    }
   ],
   "source": [
    "class Tuned(keras.Model):\n",
    "     def __init__(self):\n",
    "            super(Tuned,self).__init__()\n",
    "            self.dense1=layers.Dense(90,activation='relu')\n",
    "            self.dense2=layers.Dense(60,activation='relu')\n",
    "            self.dense3=layers.Dense(1,activation='sigmoid')\n",
    "     def call(self,inputs):\n",
    "          x=self.dense1(inputs)\n",
    "          x=self.dense2(x)\n",
    "          return self.dense3(x)\n",
    "def create_tuned():\n",
    "    inputs=keras.Input(shape=(60,))\n",
    "    Mymodel=Tuned()\n",
    "    outputs=Mymodel.call(inputs)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "#through pipeline standardize data\n",
    "np.random.seed(seed)\n",
    "estimator=[]\n",
    "estimator.append(('standardize',StandardScaler()))\n",
    "estimator.append(('mlp',KerasClassifier(build_fn=create_tuned,epochs=100,batch_size=5,verbose=0)))\n",
    "pipeline=Pipeline(estimator)\n",
    "kfold=StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(pipeline,x,encoded_y,cv=kfold)\n",
    "print(\"Full_scaled : %.2f%% (%.2f%%)\" % (result.mean()*100, result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02, 0.0371, 0.0428, ..., 0.009, 0.0032, 'R'],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0052, 0.0044, 'R'],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0095, 0.0078, 'R'],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018, ..., 0.0077, 0.0031, 'M'],\n",
       "       [0.0303, 0.0353, 0.049, ..., 0.0036, 0.0048, 'M'],\n",
       "       [0.026, 0.0363, 0.0136, ..., 0.0061, 0.0115, 'M']], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(512,activation='relu',input_shape=(60,)))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "num_val_samples = len(x) // k\n",
    "np.random.shuffle(x)\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.09% (Error)Std (12.03%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.58% (Error)Std (11.63%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.62% (Error)Std (11.17%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 48.93% (Error)Std (11.05%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.00% (Error)Std (10.68%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 50.62% (Error)Std (12.10%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 50.29% (Error)Std (11.82%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.44% (Error)Std (12.01%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.47% (Error)Std (11.69%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 49.25% (Error)Std (11.43%)\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold # ', i+1)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = encoded_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [x[:i * num_val_samples],\n",
    "      x[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [encoded_y[:i * num_val_samples],\n",
    "      encoded_y[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    model = get_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs = num_epochs, batch_size = 5, verbose = 0)\n",
    "    val_binary_crossentropy, val_adam = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_adam)\n",
    "    print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
