{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Data set\n",
    "dataframe=pd.read_csv('iris.csv',header=None)\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataframe.values\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:,0:4].astype('float')\n",
    "y=dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first encode in integer\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoder_y = encoder.transform(y)\n",
    "encoder_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode in 0 1\n",
    "dummy_y = keras.utils.to_categorical(encoder_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,activation='relu',input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline,epochs=200,batch_size=5,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10,shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 97.33% (4.42%)\n"
     ]
    }
   ],
   "source": [
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Baseline: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(4,activation='relu',input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small: 82.67% (24.07%)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_small,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Small: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_larger():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(16,activation='relu',input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 96.00% (5.33%)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_larger,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result = cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Larger: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully_Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fullyScaled():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(64,activation='relu',input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled : 88.67% (23.30%)\n"
     ]
    }
   ],
   "source": [
    "estimator=KerasClassifier(build_fn=create_fullyScaled,epochs=300,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Fully Scaled : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tuningModel():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(32,activation='relu',input_shape=(x.shape[1],)))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model : 97.33% (3.27%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_tuningModel,epochs=100,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Tuned Model : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model : 97.33% (3.27%)\n"
     ]
    }
   ],
   "source": [
    "def create_baseline():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    y=layers.Dense(8,activation='relu')(inputs)\n",
    "    output=layers.Dense(3,activation='softmax')(y)\n",
    "    \n",
    "    model=keras.Model(inputs,output)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "    \n",
    "estimator = KerasClassifier(build_fn=create_baseline,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Baseline Model : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small: 82.67% (24.07%)\n"
     ]
    }
   ],
   "source": [
    "def create_small():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    y=Dense(4,activation='relu')(inputs)\n",
    "    outputs=Dense(3,activation='softmax')(y)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_small,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Small: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 96.00% (5.33%)\n"
     ]
    }
   ],
   "source": [
    "def create_large():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    y=Dense(16,activation='relu')(inputs)\n",
    "    y=Dense(8,activation='relu')(y)\n",
    "    outputs=Dense(3,activation='softmax')(y)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_large,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result = cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Larger: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled : 88.67% (23.30%)\n"
     ]
    }
   ],
   "source": [
    "def create_fullyScaled():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    y=Dense(64,activation='relu')(inputs)\n",
    "    y=Dense(32,activation='relu')(y)\n",
    "    y=Dense(16,activation='relu')(y)\n",
    "    y=Dense(4,activation='relu')(y)\n",
    "    outputs=Dense(3,activation='softmax')(y)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator=KerasClassifier(build_fn=create_fullyScaled,epochs=300,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Fully Scaled : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model : 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "def create_tunningModel():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    y=Dense(32,activation='relu')(inputs)\n",
    "    y=Dense(16,activation='relu')(y)\n",
    "    outputs=Dense(3,activation='softmax')(y)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_tunningModel,epochs=100,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Tuned Model : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model : 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "class baseline(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(baseline,self).__init__()\n",
    "        self.dense1=Dense(8,activation='relu')\n",
    "        self.dense2=Dense(3,activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        y=self.dense1(inputs)\n",
    "        return self.dense2(y)\n",
    "    \n",
    "def create_baseline():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    Mymodel=baseline()\n",
    "    outputs=Mymodel.call(inputs)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "estimator = KerasClassifier(build_fn=create_baseline,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Baseline Model : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small: 82.67% (24.07%)\n"
     ]
    }
   ],
   "source": [
    "class small(keras.Model):\n",
    "    def __init__(self):\n",
    "        super (small,self).__init__()\n",
    "        self.dense1=Dense(4,activation='relu')\n",
    "        self.dense2=Dense(3,activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        y=self.dense1(inputs)\n",
    "        return self.dense2(y)\n",
    "def create_small():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    myModel=small()\n",
    "    outputs=myModel.call(inputs)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_small,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Small: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 96.00% (5.33%)\n"
     ]
    }
   ],
   "source": [
    "class Larger(keras.Model):\n",
    "    def __init__(self):\n",
    "        super (Larger,self).__init__()\n",
    "        self.dense1=Dense(16,activation='relu')\n",
    "        self.dense2=Dense(8,activation='relu')\n",
    "        self.dense3=Dense(3,activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        y=self.dense1(inputs)\n",
    "        y=self.dense2(y)\n",
    "        return self.dense3(y)\n",
    "def create_larger():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    myModel=Larger()\n",
    "    outputs=myModel.call(inputs)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn=create_larger,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result = cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Larger: %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Scaled : 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "class FullyScaled(keras.Model):\n",
    "    def __init__(self):\n",
    "        super (FullyScaled,self).__init__()\n",
    "        self.dense1=Dense(64,activation='relu')\n",
    "        self.dense2=Dense(16,activation='relu')\n",
    "        self.dense3=Dense(8,activation='relu')\n",
    "        self.dense4=Dense(4,activation='relu')\n",
    "        self.dense5=Dense(3,activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        y=self.dense1(inputs)\n",
    "        y=self.dense2(y)\n",
    "        y=self.dense3(y)\n",
    "        y=self.dense4(y)\n",
    "        return self.dense5(y)\n",
    "def create_fullyScaled():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    myModel=FullyScaled()\n",
    "    outputs=myModel.call(inputs)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator=KerasClassifier(build_fn=create_fullyScaled,epochs=300,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Fully Scaled : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunned Model : 96.00% (5.33%)\n"
     ]
    }
   ],
   "source": [
    "class Tuned(keras.Model):\n",
    "    def __init__(self):\n",
    "        super (Tuned,self).__init__()\n",
    "        self.dense1=Dense(32,activation='relu')\n",
    "        self.dense2=Dense(16,activation='relu')\n",
    "        self.dense3=Dense(3,activation='softmax')\n",
    "    def call(self,inputs):\n",
    "        y=self.dense1(inputs)\n",
    "        y=self.dense2(y)\n",
    "        return self.dense3(y)\n",
    "def create_tuned():\n",
    "    inputs=keras.Input(shape=(x.shape[1],))\n",
    "    myModel=Tuned()\n",
    "    outputs=myModel.call(inputs)\n",
    "    model=keras.Model(inputs,outputs)\n",
    "    model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model\n",
    "np.random.seed(seed)\n",
    "estimator=KerasClassifier(build_fn=create_tuned,epochs=200,batch_size=5,verbose=0)\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "result=cross_val_score(estimator,x,dummy_y,cv=kfold)\n",
    "print('Tunned Model : %.2f%% (%.2f%%)' % (result.mean()*100,result.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Scikit Learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "num_val_samples = len(x) // k\n",
    "np.random.shuffle(x)\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 5.00% (Error)Std (8.66%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 4.00% (Error)Std (8.00%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 3.33% (Error)Std (7.45%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 10.48% (Error)Std (18.81%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 9.17% (Error)Std (17.93%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.15% (Error)Std (17.15%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.67% (Error)Std (16.34%)\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print('processing fold # ', i+1)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = dummy_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [x[:i * num_val_samples],\n",
    "      x[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [dummy_y[:i * num_val_samples],\n",
    "      dummy_y[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    model = create_baseline()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs = 200, batch_size = 5, verbose = 0)\n",
    "    val_categorical_crossentropy, val_adam = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_adam)\n",
    "    print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 1.67% (Error)Std (2.89%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 1.33% (Error)Std (2.67%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 1.11% (Error)Std (2.48%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.86% (Error)Std (4.86%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.50% (Error)Std (4.64%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.22% (Error)Std (4.44%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.00% (Error)Std (4.27%)\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_val_samples = len(x) // k\n",
    "np.random.shuffle(x)\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold # ', i+1)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = dummy_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [x[:i * num_val_samples],\n",
    "      x[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [dummy_y[:i * num_val_samples],\n",
    "      dummy_y[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    model = create_small()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs = 200, batch_size = 5, verbose = 0)\n",
    "    val_categorical_crossentropy, val_adam = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_adam)\n",
    "    print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 13.33% (Error)Std (0.00%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 6.67% (Error)Std (6.67%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.89% (Error)Std (6.29%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 13.33% (Error)Std (9.43%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 10.67% (Error)Std (9.98%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.89% (Error)Std (9.94%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 11.43% (Error)Std (11.11%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 10.00% (Error)Std (11.06%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 9.63% (Error)Std (10.48%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.67% (Error)Std (10.35%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_val_samples = len(x) // k\n",
    "np.random.shuffle(x)\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold # ', i+1)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = dummy_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [x[:i * num_val_samples],\n",
    "      x[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [dummy_y[:i * num_val_samples],\n",
    "      dummy_y[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    model = create_larger()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs = 200, batch_size = 5, verbose = 0)\n",
    "    val_categorical_crossentropy, val_adam = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_adam)\n",
    "    print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 5.33% (Error)Std (10.67%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 4.44% (Error)Std (9.94%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 3.81% (Error)Std (9.33%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 3.33% (Error)Std (8.82%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.96% (Error)Std (8.38%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.67% (Error)Std (8.00%)\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_val_samples = len(x) // k\n",
    "np.random.shuffle(x)\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold # ', i+1)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = dummy_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [x[:i * num_val_samples],\n",
    "      x[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [dummy_y[:i * num_val_samples],\n",
    "      dummy_y[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    model =create_fullyScaled()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs = 300, batch_size = 5, verbose = 0)\n",
    "    val_categorical_crossentropy, val_adam = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_adam)\n",
    "    print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold #  1\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 0.00% (Error)Std (0.00%)\n",
      "processing fold #  2\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 3.33% (Error)Std (3.33%)\n",
      "processing fold #  3\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 2.22% (Error)Std (3.14%)\n",
      "processing fold #  4\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 1.67% (Error)Std (2.89%)\n",
      "processing fold #  5\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 1.33% (Error)Std (2.67%)\n",
      "processing fold #  6\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 1.11% (Error)Std (2.48%)\n",
      "processing fold #  7\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 4.76% (Error)Std (9.23%)\n",
      "processing fold #  8\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 5.83% (Error)Std (9.09%)\n",
      "processing fold #  9\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.89% (Error)Std (12.17%)\n",
      "processing fold #  10\n",
      "K-Fold Witout Scikit-learn : (Accuracy)Mean 8.00% (Error)Std (11.85%)\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_val_samples = len(x) // k\n",
    "np.random.shuffle(x)\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold # ', i+1)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = dummy_y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "  \n",
    "    partial_train_data = np.concatenate(                    \n",
    "      [x[:i * num_val_samples],\n",
    "      x[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "      [dummy_y[:i * num_val_samples],\n",
    "      dummy_y[(i + 1 ) * num_val_samples:]],\n",
    "    axis = 0)\n",
    "    model =create_tunningModel()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, epochs = 300, batch_size = 5, verbose = 0)\n",
    "    val_categorical_crossentropy, val_adam = model.evaluate(val_data, val_targets, verbose = 0)\n",
    "    all_scores.append(val_adam)\n",
    "    print(\"K-Fold Witout Scikit-learn : (Accuracy)Mean %.2f%% (Error)Std (%.2f%%)\" % (np.mean(all_scores)*100, np.std(all_scores)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
